{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ungraded Lab: Huber Loss\n",
    "\n",
    "In this lab, we'll walk through how to create custom loss functions. In particular, we'll code the [Huber Loss](https://en.wikipedia.org/wiki/Huber_loss) and use that in training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0p84I7yFHRT2"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "\n",
    "Our dummy dataset is just a pair of arrays `xs` and `ys` defined by the relationship $y = 2x - 1$. `xs` are the inputs while `ys` are the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "\n",
    "# labels\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc62c332e50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Let's build a simple model and train using a built-in loss function like the `mean_squared_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2eY7fw0EHwda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.98216]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "model.fit(xs, ys, epochs=500,verbose=0)\n",
    "\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss\n",
    "\n",
    "Now let's see how we can use a custom loss. We first define a function that accepts the ground truth labels (`y_true`) and model predictions (`y_pred`) as parameters. We then compute and return the loss value in the function definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHtDxE0lI_Hg"
   },
   "outputs": [],
   "source": [
    "def my_huber_loss(y_true, y_pred):\n",
    "    threshold = 1\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) <= threshold\n",
    "    small_error_loss = tf.square(error) / 2\n",
    "    big_error_loss = threshold * (tf.abs(error) - (0.5 * threshold))\n",
    "    return tf.where(is_small_error, small_error_loss, big_error_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the loss function is as simple as specifying the loss function in the `loss` argument of `model.compile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K7rgmb5qH5QX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.97061]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.compile(optimizer='sgd', loss=my_huber_loss)\n",
    "model.fit(xs, ys, epochs=1000,verbose=0)\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "first-loss.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
